#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Jan 17 16:15:56 2023

@author: magoncal
"""

import pandas as pd
import numpy as np
import os, shutil
import time

from Bio import SeqIO, SearchIO
from Bio.SubsMat.MatrixInfo import blosum62 as blosum
blosum.update(((b,a),val) for (a,b),val in list(blosum.items()))

from concurrent.futures import ProcessPoolExecutor
from concurrent.futures import wait

AA_CODE_LIST = ['?','A','R','N','D','C','Q','E','G','H','I','L','K','M','F','P','S','T','W','Y','V','U','O','B','Z','X']
AA_CODE_DICT = {'A':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'K':9,'L':10,'M':11,'N':12,'P':13,'Q':14,'R':15,'S':16,'T':17,'V':18,'W':19,'Y': 20,'U':21,'O':22,'B':23,'Z':24,'X':25}
AA_GROUPS = [[14,18,1,15,20,11,10,13,21], [19,8,16,17,5,3,6,22,12,2,9,4,7], [25]]
AA_GROUPS_NAMES = ['N','P','O']

AA_GROUPS1 = [[14,18,1,15,20,11,10,13,21],[19,8,16,17,5,3,6,22], [12,2,9], [4,7], [25]]
AA_GROUPS_NAMES1 = ['N','P','B','A','O']

path = '/home/magoncal/Documents/data/projects/idr_cook/refract_chile/refract-data/results_MBS3/'
path_out = '/home/magoncal/Documents/data/projects/idr_cook/refract_chile/refract-data/'
path_temp = path_out+"temp_marb/"

def transform_time(start, end):
    ''' Transforms the time outputs generated by times to hh:mm:ss '''
    hours, rem = divmod(end-start, 3600)
    minutes, seconds = divmod(rem, 60)
    str_time = ("{:0>2}:{:0>2}:{:05.2f}".format(int(hours),int(minutes),seconds))
    return(str_time)


def sep_peptide(peptide):
    return pd.Series((aa for aa in peptide))


def get_aa_type(peptide, tp_group):
    if tp_group=="tpsimp":
        group_code = AA_GROUPS
        group_name = AA_GROUPS_NAMES
    else:
        group_code = AA_GROUPS1
        group_name = AA_GROUPS_NAMES1
    reg_int = [AA_CODE_LIST.index(aa) for aa in peptide]
    idx_type = [[ind for ind, x in enumerate(group_code) if int_aa in x][0] for int_aa in reg_int]
    name_group = [group_name[name] for name in idx_type]
    name_group_concat = "".join(name_group)
    idr_group_tots = [sum([el in groups for el in reg_int]) for groups in group_code]
    all_info = [name_group_concat]+name_group+idr_group_tots
    return pd.Series((v for v in all_info))


def nt2aa(ntseq, direction):
    if direction=='-':
        ntseq = ntseq[::-1]
    ntseq = Seq(ntseq)
    return str(ntseq.translate())


def check_nts(nts):
    nts = [nt for nt in nts]
    return ('N' in np.unique(nts))


def get_unique_data(marb):

    #marb = 'acnA'
    file_ini = marb+"_"+files_ending
    file_96h = marb+"_96H_"+files_ending
    out_ini = marb+"_ini_details.csv"
    out_96h = marb+"_96h_details.csv"
    
    src_type = files_ending.split("_")[-1].split(".")[0]
    
    if src_type=="mix":
        cols=['peptide', 'nts','cnt']
    else:
        cols=['peptide', 'cnt']
    
    df_ini = pd.read_csv(path+file_ini, sep=" ", header=None, names=cols)
    df_96h = pd.read_csv(path+file_96h, sep=" ", header=None, names=cols)
        
    print('Started files: {0}\n'.format(marb))
    
    cols = ['res40', 'res43', 'res44', 'res90', 'res91', 'res94']
    df_ini[cols] = df_ini.apply(lambda x: sep_peptide(x['peptide']), axis=1)
    df_96h[cols] = df_96h.apply(lambda x: sep_peptide(x['peptide']), axis=1)
    tp_groups = ['tpsimp', 'tpdet']
    for tp_group in tp_groups:
        cols = ['peptide_'+tp_group, 'res40_'+tp_group, 'res43_'+tp_group, 
                'res44_'+tp_group, 'res90_'+tp_group, 'res91_'+tp_group, 'res94_'+tp_group,
                'cnt_'+tp_group+'_nonpolar', 'cnt_'+tp_group+'_polar']
        if (tp_group == 'tpdet'):
            cols = cols+['cnt_'+tp_group+'_basic', 'cnt_'+tp_group+'_acidic']
        cols.append('cnt_'+tp_group+'_other')
        df_ini[cols] = df_ini.apply(lambda x: get_aa_type(x['peptide'], tp_group), axis=1)
        df_96h[cols] = df_96h.apply(lambda x: get_aa_type(x['peptide'], tp_group), axis=1)
    
    # Check for invalid characters in the marbox, when available
    df_ini['invalid_nt'] = df_ini.apply(lambda x: check_nts(x['nts']), axis=1)
    df_96h['invalid_nt'] = df_96h.apply(lambda x: check_nts(x['nts']), axis=1)
    
    df_ini['marbox'] = marb
    df_96h['marbox'] = marb
           
    df_ini.to_csv(path_temp+out_ini, index=False)
    df_96h.to_csv(path_temp+out_96h, index=False)
      

if __name__=="__main__":
    
    start_time_all = time.time()
    
    files_ending = "unique_mix.txt"
    
    files = sorted([os.path.split(f.path)[1] for f in os.scandir(path) if f.path.endswith(files_ending)])
    marboxes = np.unique([name.split("_")[0] for name in files]).tolist()
    
    if os.path.isdir(path_temp):
        shutil.rmtree(path_temp)
    if not os.path.isdir(path_temp):
        os.makedirs(path_temp)
        
    with ProcessPoolExecutor(cores) as executor:
        tasks = [executor.submit(get_unique_data, m) for m in marboxes]   
        done, not_done = wait(tasks)
        
    if len(done)==int(len(files)/2):
        
        i=0
        files_temp_ini = sorted([f.path for f in os.scandir(path_temp) if f.path.endswith("ini_details.csv")])
        files_temp_96h = sorted([f.path for f in os.scandir(path_temp) if f.path.endswith("96h_details.csv")])
        
        for f in range(0,len(files_temp_ini)):
            df_temp_ini = pd.read_csv(files_temp_ini[f])
            df_temp_96h = pd.read_csv(files_temp_96h[f])
            if (i==0):
                df_ini_all = df_temp_ini
                df_96h_all = df_temp_96h
            else:
                df_ini_all = pd.concat([df_ini_all, df_temp_ini])
                df_96h_all = pd.concat([df_96h_all, df_temp_96h])
            i+=1
        df_ini_all.to_csv(path_out+"all_ini_details.csv", index=False)
        df_96h_all.to_csv(path_out+"all_96h_details.csv", index=False)
        
    shutil.rmtree(path_temp)
    
    time_formated = transform_time(start_time_all, time.time())
    print("Total time: {0}".format(time_formated))


def testing_metrics():

    df_ini_all = pd.read_csv(path_out+"all_ini_details.csv")
    df_96h_all = pd.read_csv(path_out+"all_96h_details.csv")
    
    #df_ini_all_X = df_ini_all.loc[df_ini_all['cnt_tpsimp_other']>0, :]
    #df_ini_all_X = (df_ini_all_X[['promoter']].groupby(['promoter'])['promoter'].count().reset_index(name='count').sort_values(['count'], ascending=False))
    #sum(df_ini_all_X['count'])

    #df_96h_all_X = df_96h_all.loc[df_96h_all['cnt_tpsimp_other']>0, :]
    #df_96h_all_X = (df_96h_all_X[['promoter']].groupby(['promoter'])['promoter'].count().reset_index(name='count').sort_values(['count'], ascending=False))
    #sum(df_96h_all_X['count'])
    
    df_ini_all = df_ini_all.loc[df_ini_all['cnt_tpsimp_other']==0, :]
    df_96h_all = df_96h_all.loc[df_96h_all['cnt_tpsimp_other']==0, :]
    
    
    df_ini_all10 = df_ini_all.groupby('promoter').head(1000).reset_index(drop=True)
    df_96h_all10 = df_96h_all.groupby('promoter').head(1000).reset_index(drop=True)
    
    def prep_calc_hamming_distance(targets):
        mat_targets = np.tile(np.array([targets]).transpose(), (1,len(targets)))
        arr_targets = np.array(targets).T
        hamm = np.array([calc_hamming_distance(i,j) for i, j in it.product(arr_targets, repeat=2)])
        hamm2 = np.array(hamm).reshape((len(arr_targets), len(arr_targets)))
        bool_val1 = (hamm>3)&(hamm<6)
        marb_sel = np.array([i for i in it.product(arr_targets, repeat=2)])[bool_val1, :]
        sop = np.array([sum(calc_sum_of_pairs(i, j, blosum, -1, -1)) for i, j in it.product(arr_targets, repeat=2)])
        sop2 = np.array(sop).reshape((len(arr_targets), len(arr_targets)))
        for v in range(0, len(arr_targets)):
            idx = (-sop2[v,:]).argsort()
            names = ", ".join(arr_targets[idx][1:])
            vals = (-np.sort(-sop2[v,:]))[1:]
            _, counts = np.unique(vals, return_counts=True)
            
            
        sop_ord = sop2[0, :].argsort()
        sop3 = sop2[:, sop2[0, :].argsort()]
    
    df_ini_all10["hamm_dist"] = df_ini_all10.apply(lambda x: calc_hamming_distance(x["str1"], x["str2"]) if len(x["str1"])>0 else np.nan, axis=1)
    df_ini_all10['sum_of_pairs'] = df_ini_all10.apply(lambda x: sum(calc_sum_of_pairs(x["str1"], x["str2"], blosum, -5, -1)) if len(x["str1"])>0 else np.nan, axis=1)
    
    
    def calc_hamming_distance(string1, string2): 
        distance = 0
        L = len(string1)
        for i in range(L):
            if string1[i] != string2[i]:
                distance += 1
        return len(string1)-distance
    
    
    def calc_sum_of_pairs(seq1, seq2, matrix, gap_s, gap_e, gap = False):
        if len(seq1)>0:
            for A,B in zip(seq1, seq2):
                diag = ('-'==A) or ('-'==B)
                yield (gap_e if gap else gap_s) if diag else matrix[(A,B)]
                gap = diag