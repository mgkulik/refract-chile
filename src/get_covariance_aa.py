#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Mar  1 13:45:01 2023

Execute file extract_counts.py BEFORE execute this step!!!

@author: magoncal
"""

import pandas as pd
import numpy as np
import os, shutil
import time
import re
from itertools import combinations, product, permutations

# Parallel execution
from concurrent.futures import ProcessPoolExecutor
from concurrent.futures import wait
from multiprocessing import cpu_count

np.set_printoptions(suppress=True)

CORES = input('Inform number of cores. Maximum is {0}: '.format(cpu_count()))
CORES = int(CORES)

SIGMA = input('Define sigma as a number. Suggested is 0.02 (1/50): ')
SIGMA = float(SIGMA)

source_int = input('Inform the target folder. 1: "withMUTATIONS" and 2: "noMUTATIONS": ')
assert(source_int=='1' or source_int=='2'), "Values must be 1 or 2."
if source_int=='1':
    SOURCE = "withMUTATIONS"
else:
    SOURCE = "noMUTATIONS"
del source_int
    
path_in = os.path.join(os.path.dirname(os.getcwd()),'refract-data', SOURCE)+'/'
assert(os.path.exists(path_in)), "Make sure extract_counts.py was executed \nand this path exists with writing permissions:\n{0}".format(path_in)

save_csv = input('Do you want to save extra csv files with counts and deltaE?\nThis is usefull to validation purposes.\n0: No and 1: Yes: ')
assert(save_csv=='0' or save_csv=='1'), "Values must be 0 or 1."
save_csv = bool(int(save_csv))

# Marbox order is fixed to make sure all outputs are the same
MARBOXES = ["marRAB", "yba0", "rob", "acnA", "acrAB", "fldB", "fldA", "fpr", "hdeA", "mdtG", "poxB", "purA", "ribA", "slp"]

AA_ORDER1 = ['C','F','W','Y']
AA_ORDER1_IDX = {'C':0,'F':1,'W':2,'Y':3}
AA_ORDER2 = ['A','R','N','D','Q','E','G','H','I','L','K','M','P','S','T','V']
AA_ORDER2_IDX = {'A':0,'R':1,'N':2,'D':3,'Q':4,'E':5,'G':6,'H':7,'I':8,'L':9,'K':10,'M':11,'P':12,'S':13,'T':14,'V':15}
AA_ORDER3 = ['A','R','N','D','C','Q','E','G','H','I','L','K','M','F','P','S','T','W','Y','V']
AA_CODE_DICT = {'A':0,'R':1,'N':2,'D':3,'C':4,'Q':5,'E':6,'G':7,'H':8,'I':9,'L':10,'K':11,'M':12,'F':13,'P':14,'S':15,'T':16,'W':17,'Y':18,'V':19}


def transform_time(start, end):
    ''' Transforms the time outputs generated by time to hh:mm:ss '''
    hours, rem = divmod(end-start, 3600)
    minutes, seconds = divmod(rem, 60)
    str_time = ("{:0>2}:{:0>2}:{:05.2f}".format(int(hours),int(minutes),seconds))
    return(str_time)


def clean_invalid(df):
    ''' Removes invalid peptides and re-summarizes the counts when counts with
    marboxes are provided.'''
    if 'invalid_nt' in df.columns:
        df = df.loc[(df.cnt_tpsimp_other==0)&(~df.invalid_nt), :]
        df = df.drop(columns=['invalid_nt', 'nts'])
        df = (df.groupby(list(df.columns[df.columns!='cnt']))['cnt'].sum()).reset_index()
    return df

def get_squared_matrix(df, marb, pair):
    ''' Extracts only the source and target column, completing the missing
    pair of residues.
    Returns a matrix of the counts.'''
    # Had to add extra step to deal with differences of AA in the first position
    # (4) compared to remaining positions (16)
    first_pos = pair[0]==cols_helix[0]
    if first_pos:
        cond = (df.marbox==marb)&(df[pair[0]].isin(AA_ORDER1))&(df[pair[1]].isin(AA_ORDER2))
        indexes = pd.MultiIndex.from_product([AA_ORDER1, AA_ORDER2], names=['aa1', 'aa2'])
    else:
        cond = (df.marbox==marb)&(df[pair[0]].isin(AA_ORDER2))&(df[pair[1]].isin(AA_ORDER2))
        indexes = pd.MultiIndex.from_product([AA_ORDER2, AA_ORDER2], names=['aa1', 'aa2'])
    
    df_out = df.loc[cond, [pair[0], pair[1], 'cnt']]
    df_out = df_out.rename({pair[0]: 'aa1', pair[1]: 'aa2', 'cnt':'cnt'}, axis='columns')
    df_out = (df_out.groupby(['aa1', 'aa2'])['cnt'].sum()).reset_index()
    # Only pivot would not solve if a pair is missing
    df_out = df_out.set_index(['aa1', 'aa2']).reindex(indexes, fill_value=0).reset_index()
    df_out = df_out.pivot(index='aa1', columns='aa2', values='cnt')
    df_out = df_out.loc[:, AA_ORDER2]
    if first_pos:
        df_out = df_out.reindex(AA_ORDER1)
    else:
        df_out = df_out.reindex(AA_ORDER2)
    return df_out #(df_out.to_numpy())


def get_rel_counts(df):
    ''' Calculatea the relative counts of the provided dataframe. '''
    sum_aa1 = np.sum(df, axis=1)
    df_rel = np.transpose(np.transpose(df)/sum_aa1)
    # Step required to remove NAs and avoid division by zero.
    df_rel = np.nan_to_num(df_rel)
    return df_rel, sum_aa1


def arr2df(arr):
    df = pd.DataFrame(arr, columns = AA_ORDER2)
    if len(df)==4:
        replacements = {l1:l2 for l1, l2 in zip(list(df.index), AA_ORDER1)}
        df = df.rename(replacements)
    else:
        replacements = {l1:l2 for l1, l2 in zip(list(df.index), AA_ORDER2)}
        df = df.rename(replacements)
    return df


def gather_counts(df_cnts, marb, pair, tp, df_all=''):
    df = df_cnts.copy()
    if tp!='':
        tp = tp+'_'
    df['step'] = marb+'_'+tp+pair[0].replace('res','')+'_'+pair[1].replace('res','')
    df = df.reset_index().rename(columns={'aa1':'aa'})
    if len(df_all)==0:
        df_all = df
    else:
        df_all = df_all.append(df, ignore_index=True)
    return df_all


def gen_pept_combinations():
    ''' Generates all possible combinations of 4+16^4 amino acids respecting the exclusion
    criterias. Returns the matrix index and the peptides themselves. '''
    # The simple sum between matrices will not work in this scenario because we need
    # the combination of all different indexes accross the dimensions for just specific
    # positions. Using matrices for combinatorial arrangemnet didn't work because of
    # lack of memory.    
    lst_idx_pept, lst_pept = [], []
    for i in product(AA_ORDER3, repeat=6): #range(0,16), repeat=6):
        if (i[0] in AA_ORDER1):
            # Check if any of the 4 not allowed AAs is present between positions 1 and 5
            check_pept2 = len([x for x in i[1:] if x not in AA_ORDER1])
            # Saves only allowed peptides and indexes
            if check_pept2==5:
                idx = [AA_ORDER1_IDX[i[0]]]+[AA_ORDER2_IDX[j] for j in i[1:]]
                lst_idx_pept.append(idx)
                lst_pept.append(''.join([j for j in i]))
    lst_idx_pept = np.array(lst_idx_pept)
    return lst_idx_pept, lst_pept


# Call this function inside function generate_scores if needed
def generate_all_comb(mat_deltaE_1, mat_deltaE_2, path_in, marb):
    ''' Generate all possible combinations of peptide respecting the restriction
    4 in pos40 and 16 in all others, calculate the scores and save to disk.'''

    lst_idx_pept, lst_pept = gen_pept_combinations()

    # It can take 4 minutes per marbox and generate big files.
    start_time_all = time.time()
    dict_deltaE = dict()
    for pept_idx, pept in zip(lst_idx_pept, lst_pept):
    
        # Getting all combinations inside the 6 positions peptide
        pairs_pept = list(combinations(pept_idx, 2))
        # Extracting indexes for matrix 1 (4x16)
        idx1 = np.array([[i]+list(j) for i,j in zip(range(5), pairs_pept[0:5])])
        # Extracting indexes for matrix 2 (16x16)
        idx2 = np.array([[i]+list(j) for i,j in zip(range(10), pairs_pept[5:])])
        sum_deltaE = np.sum(mat_deltaE_1[idx1[:, 0],idx1[:, 1], idx1[:,2]])+np.sum(mat_deltaE_2[idx2[:, 0],idx2[:, 1], idx2[:,2]])
        dict_deltaE[pept] = sum_deltaE
        
    time_formated = transform_time(start_time_all, time.time())
    print("Total time: {0}".format(time_formated))
    
    path_comp = path_in+"covariance_aa_aa/deltaE/"
    if not os.path.isdir(path_comp):
        os.makedirs(path_comp)
    
    df_deltaE = pd.DataFrame.from_dict(dict_deltaE, orient='index', columns=['deltaE']).reset_index().rename(columns={'index':'peptide'})
    df_deltaE = df_deltaE.sort_values(['deltaE'], ascending=True)
    df_deltaE.to_csv(path_comp+marb+"_peptides_all_deltaE.tab", index=False, sep="\t")


def generate_score_matrices(marb):
    ''' Main function to generate scores. It replaces a for loop with a multiprocessing
    function. Generate the count tables '''
    
    start_time = time.time()
    
    # Initialize the matrices in two different sizes 4X16 when res40 is used (5 matrices)
    mat_deltaE_1 = np.empty([(len(cols_helix)-1), len(AA_ORDER1), len(AA_ORDER2)])
    # 16X16 for the rest of the combinations (10 matrices)
    mat_deltaE_2 = np.empty([len(col_pairs)-(len(cols_helix)-1), len(AA_ORDER2), len(AA_ORDER2)])
    df_all_obs, df_all_exp, df_all_deltaE = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
    for i in range(0,len(col_pairs)):
        
        # Extract and populate the matrices
        ar_obs = get_squared_matrix(df_ini, marb, col_pairs[i])
        ar_rel_obs, _ = get_rel_counts(ar_obs)
        if save_csv:
            df_all_obs = gather_counts(ar_obs, marb, col_pairs[i], 'ini', df_all_obs)
        
        ar_exp = get_squared_matrix(df_96h, marb, col_pairs[i])
        ar_rel_exp, sums_exp = get_rel_counts(ar_exp)
        sums_exp = np.array(sums_exp)
        if save_csv:
            df_all_exp = gather_counts(ar_exp, marb, col_pairs[i], '96h', df_all_exp)
        
        # Calculate the ratio
        ar_ratio = ar_rel_exp/ar_rel_obs
        ar_ratio[ar_ratio == np.inf] = 0 # Had to do it manually because nan_to_num wasn't handling it properly
        ar_ratio = np.nan_to_num(ar_ratio)
        deltaE = np.nan_to_num(np.transpose(np.log(1+sums_exp*SIGMA)-np.log(1+sums_exp*SIGMA*np.transpose(ar_ratio))))
        if save_csv:
            df_all_deltaE = gather_counts(arr2df(deltaE), marb, col_pairs[i], '', df_all_deltaE)
        
        if (col_pairs[i][0]==cols_helix[0]):
            mat_deltaE_1[i,:,:] = deltaE
        else:
            # Had to adjust the rowindex because both arrays start in zero
            # and the 5 first executions belong to matrix1
            mat_deltaE_2[i-len(mat_deltaE_1),:,:] = deltaE        
    
    if save_csv:
        path_comp = path_in+'covariance_aa_aa/'
        if not os.path.isdir(path_comp):
            os.makedirs(path_comp)
        
        # Saving counts in human readable format
        df_all_obs.to_csv(path_comp+marb+"_ini_counts.csv", index=False)
        df_all_exp.to_csv(path_comp+marb+"_96h_counts.csv", index=False)
        df_all_deltaE.to_csv(path_comp+marb+"_ratios.csv", index=False)
    
    path_comp = path_in+'covariance_aa_aa/sources/'
    if not os.path.isdir(path_comp):
        os.makedirs(path_comp)
    
    np.save(path_comp+marb+'_ratios_pos1.npy', mat_deltaE_1)
    np.save(path_comp+marb+'_ratios_posN.npy', mat_deltaE_2)
    
    #generate_all_comb(mat_deltaE_1, mat_deltaE_2, path_in, marb)
    
    time_formated = transform_time(start_time, time.time())
    print("Total time for {0}: {1}".format(marb, time_formated))
    

if __name__ == '__main__':
    
    start_time_all = time.time()

    df_ini = pd.read_csv(path_in+"all_ini_details.csv")
    df_96h = pd.read_csv(path_in+"all_96h_details.csv")

    # Step required when AA residues with marboxes where provided
    # because we may have invalid nucleic acids in the marboxes
    df_ini = clean_invalid(df_ini)
    df_96h = clean_invalid(df_96h)

    # Get all combinations of columns
    cols_helix = [re.search('res\d+$', col)!=None for col in list(df_ini.columns)]
    cols_helix = [i for (i, v) in zip(list(df_ini.columns), cols_helix) if v]
    col_pairs = list(combinations(cols_helix, 2))
    
    with ProcessPoolExecutor(CORES) as executor:
        tasks = [executor.submit(generate_score_matrices, m) for m in MARBOXES]   
        done, not_done = wait(tasks)
        
    time_formated = transform_time(start_time_all, time.time())
    print("\nTotal time: {0}".format(time_formated))
    print("\nAll score matrices saved to disk.")